# Contexto Geral
Este reposit√≥rio cont√©m o c√≥digo-fonte do desafio 3, que √© um agente inteligente capaz de responder a perguntas sobre arquivos de dados (CSV e Excel), utilizando uma interface amig√°vel para o usu√°rio. O objetivo principal foi criar uma solu√ß√£o que permitisse a intera√ß√£o em linguagem natural com os dados, sem a necessidade de conhecimento t√©cnico em manipula√ß√£o de planilhas ou programa√ß√£o
# Frameworks & Tools
- LangChain
- Google Gemini (via langchain-google-genai)
- Python
- Streamlit
- Pandas
- python-dotenv
- zipfile
- langchain-experimental
- tabulate

# Estrutura da Solu√ß√£o
A solu√ß√£o foi estruturada em um programa Python `app.py` que utiliza os conceitos de agentes e ferramentas do LangChain, orquestrados por uma interface web do Streamlit.
A arquitetura do agente segue os seguintes passos:

# Interface do Usu√°rio (Streamlit):
Uma aplica√ß√£o web simples √© iniciada, fornecendo campos para o usu√°rio inserir a pasta dos dados (opcional) ou fazer upload de arquivos diretamente. 
H√° um campo de texto para o usu√°rio digitar sua pergunta e um bot√£o para "Obter Resposta". 

# Fluxo do app:
1. Ao iniciar ou quando arquivos s√£o carregados, o agente verifica a pasta de dados configurada (./data por padr√£o). Ele possui uma fun√ß√£o `unpack_zip_files` para descompactar automaticamente quaisquer arquivos .zip encontrados, garantindo que os arquivos CSV/Excel estejam acess√≠veis. 
2. Uma fun√ß√£o `find_data_file` tenta identificar o arquivo de dados mais relevante para a pergunta do usu√°rio. Atualmente, essa fun√ß√£o usa uma l√≥gica baseada em palavras-chave no nome do arquivo e na pergunta, ou seleciona o primeiro arquivo dispon√≠vel. 
3. A API Key do Google Gemini √© carregada de forma segura a partir de um arquivo .env (ocultada e n√£o versionada). 
4. O LLM (e.g., gemini-1.5-pro-latest) √© inicializado usando o objeto `ChatGoogleGenerativeAI`, que serve como o "c√©rebro" do agente para entender as perguntas e formular as respostas.
5. Para cada pergunta, o arquivo de dados relevante √© carregado em um `Pandas` `DataFrame`. 
6. √â criado um `create_pandas_dataframe_agent` do LangChain, que √© um tipo de agente especializado em interagir com DataFrames. Este agente recebe o LLM e o DataFrame como entrada. 
7. Quando o usu√°rio submete uma pergunta, o agente a processa. Internamente, o LLM recebe a pergunta e o "contexto" do DataFrame (incluindo o cabe√ßalho e algumas linhas de exemplo). 
8. O LLM, ent√£o, "pensa" sobre como responder √† pergunta usando as opera√ß√µes do Pandas (como filtrar, somar, agrupar, encontrar o m√°ximo/m√≠nimo).
9. Esse processo de "pensamento" √© vis√≠vel no terminal (verbose=True). 
10. O agente executa as opera√ß√µes do Pandas necess√°rias nos dados reais. 
Finalmente, o agente usa o LLM para formatar a resposta de forma compreens√≠vel ao usu√°rio e a exibe na interface do Streamlit.

# Guia T√©cnico: Streamlit, Google Gemini e LangChain para Aplica√ß√µes de IA

Este guia t√©cnico demonstra como integrar Streamlit para constru√ß√£o de interfaces web interativas, Google Gemini como modelo de linguagem poderoso e LangChain para orquestrar e gerenciar as intera√ß√µes com o modelo. Ao final, voc√™ ter√° as ferramentas e o conhecimento para desenvolver aplica√ß√µes de IA robustas e din√¢micas.

# Pr√©-requisitos e Instala√ß√£o
Para come√ßar, certifique-se de ter o Python instalado (vers√£o 3.9 ou superior √© recomendada). Em seguida, instale as bibliotecas necess√°rias:

```bash
pip install streamlit
pip install google-generative-ai
pip install langchain
pip install langchain-experimental
pip install python-dotenv  # Para gerenciar vari√°veis de ambiente de forma segura
pip install pandas
pip install zipfile
```
# Configurando o Google Gemini
Para utilizar o Google Gemini, voc√™ precisar√° de uma API Key. Siga os passos abaixo para obt√™-la e configur√°-la:

Obtenha sua API Key: Acesse o Google AI Studio - https://aistudio.google.com/ - e siga as instru√ß√µes para criar um novo projeto e gerar sua API Key. 
Armazenamento Seguro: Nunca exponha sua API Key diretamente no c√≥digo. A melhor pr√°tica √© armazen√°-la em um arquivo .env e carreg√°-la usando a biblioteca python-dotenv.
Configurar Arquivo .env: Crie um arquivo .env na raiz do seu projeto com o seguinte conte√∫do:

   
 GOOGLE_API_KEY="SUA_API_KEY_AQUI"

   Substitua "SUA_API_KEY_AQUI" pela sua chave de API real.
Introdu√ß√£o ao Streamlit
Streamlit √© um framework de c√≥digo aberto para criar rapidamente aplica√ß√µes web para ci√™ncia de dados e aprendizado de m√°quina. Ele permite transformar scripts Python em apps interativos com poucas linhas de c√≥digo.

Exemplo B√°sico de Streamlit:
Crie um arquivo app.py:

```python
import streamlit as st

st.title("Meu Primeiro App Streamlit")
st.write("Bem-vindo ao Streamlit!")

user_input = st.text_input("Digite algo aqui:", "Ol√°, mundo!")
st.write(f"Voc√™ digitou: {user_input}")

if st.button("Clique-me"):
    st.success("Bot√£o clicado!")
```

Para rodar o aplicativo, execute no terminal:

```bash
streamlit run app.py
```

Seu navegador abrir√° automaticamente a aplica√ß√£o no endere√ßo `localhost:8051`.
Utilizando o Google Gemini com LangChain
LangChain √© um framework projetado para simplificar o desenvolvimento de aplica√ß√µes alimentadas por modelos de linguagem. Ele fornece abstra√ß√µes e ferramentas para encadear diferentes componentes (modelos de linguagem, prompts, ferramentas, etc.) de forma eficiente.

# Configurando o Gemini com LangChain
Primeiro, vamos configurar o modelo Gemini no LangChain e carregar nossa API Key.

```python
# Em seu arquivo Python (ex: main.py ou app.py)
import os
import streamlit as st
from dotenv import load_dotenv
from langchain_google_genai import 
ChatGoogleGenerativeAI # Importa√ß√£o ajustada para a vers√£o mais recente do LangChain

load_dotenv()  # Carrega as vari√°veis de ambiente do .env

# Configura a chave da API do Google Gemini
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    st.error("Erro: A vari√°vel de ambiente GOOGLE_API_KEY n√£o est√° configurada.")
    st.stop()

# Inicializa o modelo Gemini com LangChain
llm = ChatGoogleGenerativeAI(model="gemini-pro", google_api_key=GOOGLE_API_KEY)

# Exemplo de uso direto do modelo Gemini
# response = llm.invoke("Qual √© a capital do Brasil?")
# print(response.content)
```

Nota: A importa√ß√£o para o modelo Gemini no LangChain pode variar ligeiramente dependendo da vers√£o espec√≠fica da biblioteca `langchain_google_genai`. Certifique-se de que a o comando `import from langchain_google_genai import ChatGoogleGenerativeAI` est√° correta para sua instala√ß√£o.
Criando um Sistema de Perguntas e Respostas com LangChain Chains
Vamos construir um sistema simples de perguntas e respostas usando um LLMChain do LangChain.

```python
# Adicione este c√≥digo ao seu arquivo main.py ou app.py

from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import LLMChain

# Define o template do prompt para o modelo Gemini
prompt_template = ChatPromptTemplate.from_template("Responda √† seguinte pergunta de forma concisa: {question}")

# Cria uma LLMChain que combina o prompt e o modelo
qa_chain = LLMChain(llm=llm, prompt=prompt_template)

# Exemplo de uso da chain
# question = "Qual a import√¢ncia da intelig√™ncia artificial?"
# response_chain = qa_chain.invoke({"question": question})
# print(response_chain['text'])
```
Integrando Streamlit, Google Gemini e LangChain
Agora, vamos combinar tudo para criar uma aplica√ß√£o Streamlit interativa que utiliza o modelo Gemini via LangChain para responder a perguntas.

```python
import os
import streamlit as st
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import LLMChain

# Carrega as vari√°veis de ambiente
load_dotenv()

# --- Configura√ß√£o da API do Google Gemini ---
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    st.error("Erro: A vari√°vel de ambiente GOOGLE_API_KEY n√£o est√° configurada. Crie um arquivo .env com GOOGLE_API_KEY='SUA_API_KEY'.")
    st.stop()

# --- Inicializa√ß√£o do Modelo Gemini com LangChain ---
try:
    llm = ChatGoogleGenerativeAI(model="gemini-pro", google_api_key=GOOGLE_API_KEY)
except Exception as e:
    st.error(f"Erro ao inicializar o modelo Gemini: {e}. Verifique sua API Key.")
    st.stop()

# --- Defini√ß√£o da Chain LangChain ---
prompt_template = ChatPromptTemplate.from_template("Responda √† seguinte pergunta de forma clara e √∫til: {question}")
qa_chain = LLMChain(llm=llm, prompt=prompt_template)

# --- Interface do Streamlit ---
st.set_page_config(page_title="App de Perguntas e Respostas com Gemini e LangChain", page_icon="ü§ñ")
st.title("ü§ñ App de Perguntas e Respostas com Gemini e LangChain")
st.markdown("Fa√ßa uma pergunta e deixe o Google Gemini responder!")

user_question = st.text_input("Sua pergunta:", placeholder="Ex: Qual o objetivo da miss√£o Artemis?")

if st.button("Obter Resposta"):
    if user_question:
        with st.spinner("Pensando na resposta..."):
            try:
                response = qa_chain.invoke({"question": user_question})
                st.subheader("Resposta:")
                st.write(response['text'])
            except Exception as e:
                st.error(f"Ocorreu um erro ao processar sua pergunta: {e}")
    else:
        st.warning("Por favor, digite uma pergunta.")

st.markdown("---")
st.info("Desenvolvido com Streamlit, Google Gemini e LangChain.")
```

Para executar este aplicativo, salve o c√≥digo acima como app.py e execute:

```bash
streamlit run app.py
```
Pr√≥ximos Passos e Recursos Adicionais
Este guia forneceu uma base s√≥lida para come√ßar a construir aplica√ß√µes de IA com Streamlit, Google Gemini e LangChain. Aqui est√£o algumas ideias para expandir e aprimorar seus projetos:
Hist√≥rico de Conversa (Memory): Explore os recursos de Memory do LangChain para manter o contexto em conversas multi-turn.
Ferramentas (Tools): Integre ferramentas externas (como pesquisa na web, APIs de banco de dados) via LangChain para permitir que o modelo Gemini acesse informa√ß√µes al√©m de seu conhecimento pr√©-treinado.
Agentes (Agents): Utilize Agents do LangChain para permitir que o modelo Gemini raciocine e tome decis√µes sobre quais ferramentas usar para atingir um objetivo.
Mais Modelos: Experimente outros modelos do Google Gemini ou outros LLMs compat√≠veis com LangChain.
Deployment: Aprenda a fazer o deploy de suas aplica√ß√µes Streamlit em plataformas como Streamlit Community Cloud, Hugging Face Spaces ou na nuvem (AWS, GCP, Azure).
Interface mais Complexa: Explore os componentes avan√ßados do Streamlit para criar interfaces de usu√°rio mais ricas e personalizadas.
Solu√ß√£o de Problemas Comuns
ModuleNotFoundError: Verifique se todas as bibliotecas listadas nos pr√©-requisitos foram instaladas corretamente.
google_api_key n√£o configurada: Certifique-se de que seu arquivo .env est√° na raiz do projeto e que a chave de API est√° corretamente definida. Reinicie o terminal ou o ambiente de desenvolvimento se alterou o .env recentemente.
Erros da API Gemini: Verifique sua conex√£o com a internet e se a API Key √© v√°lida. Consulte a documenta√ß√£o do Google Gemini para limites de uso ou outros problemas de servi√ßo.
Vers√µes do LangChain: O LangChain est√° em constante evolu√ß√£o. Se encontrar erros de importa√ß√£o ou uso, consulte a documenta√ß√£o oficial do LangChain para a vers√£o mais recente.

Com este guia, voc√™ est√° pronto para explorar o vasto potencial da intelig√™ncia artificial generativa e construir suas pr√≥prias aplica√ß√µes inovadoras!
